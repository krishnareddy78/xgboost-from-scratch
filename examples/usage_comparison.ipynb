{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing From-Scratch XGBoost with Standard Libraries\n",
    "\n",
    "This notebook demonstrates the usage of our custom `advanced_xgboost` implementation and compares its performance against `xgboost.XGBRegressor` and `sklearn.ensemble.GradientBoostingRegressor` on a synthetic regression dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Import our model\n",
    "from advanced_xgboost import XGBoost\n",
    "\n",
    "# Import library models for comparison\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    noise=30,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "params = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 3,\n",
    "}\n",
    "\n",
    "# --- Our Custom XGBoost ---\n",
    "xgb_custom = XGBoost(\n",
    "    n_estimators=params['n_estimators'],\n",
    "    learning_rate=params['learning_rate'],\n",
    "    max_depth=params['max_depth'],\n",
    "    min_child_weight=1,\n",
    "    lambda_reg=1.0\n",
    ")\n",
    "xgb_custom.fit(X_train, y_train)\n",
    "y_pred_custom = xgb_custom.predict(X_test)\n",
    "mse_custom = mean_squared_error(y_test, y_pred_custom)\n",
    "\n",
    "# --- Official XGBoost Library ---\n",
    "xgb_official = XGBRegressor(\n",
    "    n_estimators=params['n_estimators'],\n",
    "    learning_rate=params['learning_rate'],\n",
    "    max_depth=params['max_depth'],\n",
    "    reg_lambda=1.0,\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42\n",
    ")\n",
    "xgb_official.fit(X_train, y_train)\n",
    "y_pred_official = xgb_official.predict(X_test)\n",
    "mse_official = mean_squared_error(y_test, y_pred_official)\n",
    "\n",
    "# --- Scikit-learn Gradient Boosting ---\n",
    "gbr_sklearn = GradientBoostingRegressor(\n",
    "    n_estimators=params['n_estimators'],\n",
    "    learning_rate=params['learning_rate'],\n",
    "    max_depth=params['max_depth'],\n",
    "    random_state=42\n",
    ")\n",
    "gbr_sklearn.fit(X_train, y_train)\n",
    "y_pred_sklearn = gbr_sklearn.predict(X_test)\n",
    "mse_sklearn = mean_squared_error(y_test, y_pred_sklearn)\n",
    "\n",
    "print(f\"Custom XGBoost MSE:       {mse_custom:.4f}\")\n",
    "print(f\"Official XGBoost MSE:     {mse_official:.4f}\")\n",
    "print(f\"Scikit-learn GBR MSE:   {mse_sklearn:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred_custom, alpha=0.5, label=f'MSE: {mse_custom:.2f}')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--', color='red', lw=2)\n",
    "plt.title('Custom XGBoost: Predictions vs Actual')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_pred_official, alpha=0.5, label=f'MSE: {mse_official:.2f}', color='green')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--', color='red', lw=2)\n",
    "plt.title('Official XGBoost: Predictions vs Actual')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
